---
title: "Transformer-Maze"
collection: publications
category: thesis
permalink: /publication/2022-heuser-thesis
excerpt: ''
date: 2022-01-01
venue: 'Master’s of Engineering Thesis, Massachusetts Institute of Technology'
authors: ["Annika Heuser"]
---

<iframe
  src="/files/MEng_Thesis_aheuser.pdf"
  width="100%"
  height="600px"
  style="border: none;">
</iframe>

<a href="/files/MEng_Thesis_aheuser.pdf">Download paper</a>

**Abstract:** Psycholinguists study online language processing to gain insight into both the different mental representations of various sentence types and the computational resources
required to build those representations. Psycholinguists have a number of tools available to them, the most prevalent being eye-tracking and self-paced reading (SPR).
However, a lesser-known tool called the Maze task, more specifically G(rammatical)-
Maze, is arguably a better choice for detecting and localizing differences in processing
difficulty from word to word. In G-Maze, a participant must choose between each
successive word in sentence and a distractor word that does not make sense based
on the preceding context. If a participant chooses the distractor as opposed to the
actual word, then the trial ends and they may not complete the sentence. Like SPR,
G-Maze can be cheaply run on a crowdsourcing platform, but it does a better job of
localizing effects and filtering out noisy data. Still, the effort required to pick contextually inappropriate distractors for hundreds of words might cause an experimenter
to hesitate before picking this method. Boyce et al. (2020) remove this hesitation
with A(uto)-Maze, a tool that automatically generates distractors using a computational language model. In this thesis, we introduce the next generation of A-Maze:
T(ransformer)-Maze. Transformer models are the current state of the art in natural
language processing, and thousands, pretrained in a variety of languages, are freely
available on the internet, specifically through Huggingface’s Transformers package.
In our validation experiment, T-Maze proves itself to be as effective as G-Maze with
handmade materials, run in a lab. We are excited to provide psycholinguists with
a new tool that allows them to easily gather high-quality online sentence processing
data in many different languages.

Recommended citation: Heuser, A. (2022). Transformer-Maze. <i>Master’s of Engineering Thesis, Massachusetts Institute of Technology</i>.

<!---
paperurl: 'https://dspace.mit.edu/bitstream/handle/1721.1/147233/MEng_Thesis_aheuser.pdf?sequence=1&isAllowed=y'
citation: 'Heuser, A. (2022). "Transformer-Maze." <i>Master’s of Engineering Thesis, Massachusetts Institute of Technology</i>.'
-->